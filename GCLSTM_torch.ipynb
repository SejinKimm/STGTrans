{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjkim/anaconda3/envs/STGTrans/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "class GCLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        K (int): Chebyshev filter size :math:`K`.\n",
    "        normalization (str, optional): The normalization scheme for the graph\n",
    "            Laplacian (default: :obj:`\"sym\"`):\n",
    "\n",
    "            1. :obj:`None`: No normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
    "\n",
    "            2. :obj:`\"sym\"`: Symmetric normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
    "            \\mathbf{D}^{-1/2}`\n",
    "\n",
    "            3. :obj:`\"rw\"`: Random-walk normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
    "\n",
    "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
    "            this operator in case the normalization is non-symmetric.\n",
    "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
    "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
    "            scalar/zero-dimensional tensor when operating on single graphs.\n",
    "            You can pre-compute :obj:`lambda_max` via the\n",
    "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        K: int,\n",
    "        normalization: str = \"sym\",\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(GCLSTM, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "        self._set_parameters()\n",
    "\n",
    "    def _create_input_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_i = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_i = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_i = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_forget_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_f = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_f = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_f = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_cell_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_c = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_c = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_c = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_output_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_o = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_o = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_o = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_input_gate_parameters_and_layers()\n",
    "        self._create_forget_gate_parameters_and_layers()\n",
    "        self._create_cell_state_parameters_and_layers()\n",
    "        self._create_output_gate_parameters_and_layers()\n",
    "\n",
    "    def _set_parameters(self):\n",
    "        glorot(self.W_i)\n",
    "        glorot(self.W_f)\n",
    "        glorot(self.W_c)\n",
    "        glorot(self.W_o)\n",
    "        zeros(self.b_i)\n",
    "        zeros(self.b_f)\n",
    "        zeros(self.b_c)\n",
    "        zeros(self.b_o)\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _set_cell_state(self, X, C):\n",
    "        if C is None:\n",
    "            C = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return C\n",
    "\n",
    "    def _calculate_input_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        I = torch.matmul(X, self.W_i)\n",
    "        I = I + self.conv_i(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        I = I + self.b_i\n",
    "        I = torch.sigmoid(I)\n",
    "        return I\n",
    "\n",
    "    def _calculate_forget_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        F = torch.matmul(X, self.W_f)\n",
    "        F = F + self.conv_f(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        F = F + self.b_f\n",
    "        F = torch.sigmoid(F)\n",
    "        return F\n",
    "\n",
    "    def _calculate_cell_state(self, X, edge_index, edge_weight, H, C, I, F, lambda_max):\n",
    "        T = torch.matmul(X, self.W_c)\n",
    "        T = T + self.conv_c(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        T = T + self.b_c\n",
    "        T = torch.tanh(T)\n",
    "        C = F * C + I * T\n",
    "        return C\n",
    "\n",
    "    def _calculate_output_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        O = torch.matmul(X, self.W_o)\n",
    "        O = O + self.conv_o(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        O = O + self.b_o\n",
    "        O = torch.sigmoid(O)\n",
    "        return O\n",
    "\n",
    "    def _calculate_hidden_state(self, O, C):\n",
    "        H = O * torch.tanh(C)\n",
    "        return H\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "        C: torch.FloatTensor = None,\n",
    "        lambda_max: torch.Tensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state and cell state\n",
    "        matrices are not present when the forward pass is called these are\n",
    "        initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "            * **C** *(PyTorch Float Tensor, optional)* - Cell state matrix for all nodes.\n",
    "            * **lambda_max** *(PyTorch Tensor, optional but mandatory if normalization is not sym)* - Largest eigenvalue of Laplacian.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "            * **C** *(PyTorch Float Tensor)* - Cell state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        C = self._set_cell_state(X, C)\n",
    "        I = self._calculate_input_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        F = self._calculate_forget_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        C = self._calculate_cell_state(X, edge_index, edge_weight, H, C, I, F, lambda_max)\n",
    "        O = self._calculate_output_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        H = self._calculate_hidden_state(O, C)\n",
    "        return H, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def create_mock_data(number_of_nodes, edge_per_node, in_channels):\n",
    "    \"\"\"\n",
    "    Creating a mock feature matrix and edge index.\n",
    "    \"\"\"\n",
    "    graph = nx.watts_strogatz_graph(number_of_nodes, edge_per_node, 0.5)\n",
    "    edge_index = torch.LongTensor(np.array([edge for edge in graph.edges()]).T)\n",
    "    X = torch.FloatTensor(np.random.uniform(-1, 1, (number_of_nodes, in_channels)))\n",
    "    #X = torch.FloatTensor(np.resize(np.arange(number_of_nodes), (in_channels, number_of_nodes)).T)\n",
    "    return X, edge_index\n",
    "\n",
    "def create_mock_edge_weight(edge_index):\n",
    "    \"\"\"\n",
    "    Creating a mock edge weight tensor.\n",
    "    \"\"\"\n",
    "    return torch.FloatTensor(np.random.uniform(0, 1, (edge_index.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.nn.recurrent import GCLSTM\n",
    "\n",
    "def test_gc_lstm_layer():\n",
    "    \"\"\"\n",
    "    Testing the GCLSTM Layer.\n",
    "    \"\"\"\n",
    "    number_of_nodes = 100\n",
    "    edge_per_node = 10\n",
    "    in_channels = 64\n",
    "    out_channels = 16\n",
    "    K = 2\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X, edge_index = create_mock_data(number_of_nodes, edge_per_node, in_channels)\n",
    "    X = X.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_weight = create_mock_edge_weight(edge_index).to(device)\n",
    "\n",
    "    layer = GCLSTM(in_channels=in_channels, out_channels=out_channels, K=K).to(device)\n",
    "\n",
    "    H, C = layer(X, edge_index, edge_weight)\n",
    "\n",
    "    assert H.shape == (number_of_nodes, out_channels)\n",
    "    assert C.shape == (number_of_nodes, out_channels)\n",
    "\n",
    "    H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "\n",
    "    assert H.shape == (number_of_nodes, out_channels)\n",
    "    assert C.shape == (number_of_nodes, out_channels)\n",
    "\n",
    "    H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "\n",
    "    assert H.shape == (number_of_nodes, out_channels)\n",
    "    assert C.shape == (number_of_nodes, out_channels)\n",
    "    \n",
    "    H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "\n",
    "    assert H.shape == (number_of_nodes, out_channels)\n",
    "    assert C.shape == (number_of_nodes, out_channels)\n",
    "\n",
    "    H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "\n",
    "    assert H.shape == (number_of_nodes, out_channels)\n",
    "    assert C.shape == (number_of_nodes, out_channels)\n",
    "\n",
    "    return H, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.0323,  0.3428, -0.2118,  ...,  0.0651,  0.5945, -0.0238],\n",
      "        [ 0.3727,  0.2327, -0.0910,  ..., -0.1904,  0.4503, -0.5138],\n",
      "        [ 0.0144,  0.0845, -0.0661,  ..., -0.0485,  0.1646, -0.1593],\n",
      "        ...,\n",
      "        [-0.5774,  0.0808, -0.0353,  ..., -0.0031,  0.5244,  0.2021],\n",
      "        [-0.2700,  0.5079,  0.3706,  ...,  0.0141, -0.0491,  0.5180],\n",
      "        [-0.0474, -0.0568, -0.2530,  ..., -0.0587,  0.3075, -0.0203]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>), tensor([[-0.0889,  1.1728, -0.5472,  ...,  0.2536,  1.1242, -0.0355],\n",
      "        [ 0.5635,  1.1498, -0.3582,  ..., -1.3228,  0.9414, -0.8022],\n",
      "        [ 0.0274,  0.3380, -1.0526,  ..., -0.0832,  0.5213, -0.2658],\n",
      "        ...,\n",
      "        [-1.1701,  0.1954, -0.2491,  ..., -0.0268,  1.2052,  0.4665],\n",
      "        [-1.1908,  0.8827,  1.0925,  ...,  0.0364, -1.3365,  0.9876],\n",
      "        [-0.0873, -0.1680, -0.4009,  ..., -0.1585,  0.4510, -0.0413]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(test_gc_lstm_layer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_hop_based_subgraph_generator_BFS(k, feature_vector, adjacency_matrix):\n",
    "    N = len(feature_vector)        \n",
    "    subgraphs = []\n",
    "\n",
    "    def BFS(u):\n",
    "        visit = [False] * N\n",
    "        qu = [(u, 0)]\n",
    "        visit[u] = True\n",
    "        ret = []\n",
    "\n",
    "        while len(qu) > 0:\n",
    "            u, dist = qu.pop(0)\n",
    "            if dist > k:\n",
    "                break\n",
    "            ret.append(u)\n",
    "\n",
    "            for v in range(N):\n",
    "                if adjacency_matrix[u][v] == 1 and visit[v] == False:\n",
    "                    qu.append((v, dist + 1))\n",
    "                    visit[v] = True\n",
    "        return ret    \n",
    "    \n",
    "    for i in range(N):\n",
    "        candidate_list = BFS(i)\n",
    "        sub_feature = feature_vector[candidate_list]\n",
    "        sub_adj = adjacency_matrix[:,candidate_list][candidate_list,:]\n",
    "        subgraphs.append([sub_feature, sub_adj])\n",
    "    return subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def src_city_model():\n",
    "\n",
    "    number_of_nodes = 4\n",
    "    edge_per_node = 2\n",
    "    \n",
    "    in_channels = 64\n",
    "    out_channels = 16\n",
    "    K = 2\n",
    "    k = 1\n",
    "    number_of_layers = 5\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X, edge_index = create_mock_data(number_of_nodes, edge_per_node, in_channels)\n",
    "    X = X.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_weight = torch.FloatTensor(np.ones(edge_index.shape[1])).to(device)\n",
    "    adj = torch.FloatTensor(np.zeros((number_of_nodes, number_of_nodes))).to(device)\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        adj[edge_index[0][i]][edge_index[1][i]] = edge_weight[i]\n",
    "        adj[edge_index[1][i]][edge_index[0][i]] = edge_weight[i]\n",
    "    \n",
    "    print(X)\n",
    "    print(adj)\n",
    "\n",
    "    subgraph = k_hop_based_subgraph_generator_BFS(k, X, adj)\n",
    "    subGCLSTM = []\n",
    "\n",
    "    for sub_feature, sub_adj in subgraph:\n",
    "        layer = GCLSTM(in_channels=in_channels, out_channels=out_channels, K=K).to(device)\n",
    "\n",
    "        edges = []\n",
    "        for i in range(len(sub_adj)):\n",
    "            for j in range(len(sub_adj[0])):\n",
    "                if sub_adj[i][j] == 1:\n",
    "                    edges.append([i, j])\n",
    "        \n",
    "        X = sub_feature\n",
    "        edge_index = torch.LongTensor(np.array(edges).T).to(device)\n",
    "        edge_weight = torch.FloatTensor(np.ones(edge_index.shape[1])).to(device)\n",
    "        \n",
    "        #print(X.shape)\n",
    "        #print(edge_index.shape)\n",
    "        #print(edge_weight.shape)\n",
    "\n",
    "        for i in range(number_of_layers):\n",
    "            if i == 0:\n",
    "                H, C = layer(X, edge_index, edge_weight)\n",
    "            else:\n",
    "                H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "\n",
    "            #print(\"!!!! Layer %d !!!!\" % (i+1))\n",
    "            #print(H.shape, C.shape)\n",
    "        \n",
    "        #subGCLSTM.append([H, C])\n",
    "        subGCLSTM.append(H[0])\n",
    "    \n",
    "    subGCLSTM = torch.stack(subGCLSTM, 0)\n",
    "    \n",
    "    return subGCLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1266e-01, -8.6506e-01,  2.3652e-01, -6.4157e-02,  9.0521e-02,\n",
      "         -1.4844e-01, -8.5602e-01, -7.8615e-01,  1.3495e-01,  7.5214e-01,\n",
      "          9.4506e-01, -4.6812e-01,  5.2390e-01, -5.6317e-01,  4.4783e-01,\n",
      "          7.8202e-01, -7.0438e-01, -4.3343e-01,  7.4851e-01,  4.5329e-01,\n",
      "          1.0470e-01,  5.4400e-01, -2.0877e-01,  6.1310e-01, -8.2077e-01,\n",
      "          1.3996e-01, -2.4717e-01,  5.1435e-01,  8.8744e-01,  7.9021e-02,\n",
      "         -9.9111e-01,  7.0411e-01,  8.5922e-01, -9.4183e-01,  6.7335e-01,\n",
      "          8.0959e-01, -4.8604e-02, -5.1650e-01,  4.0393e-01,  5.1963e-03,\n",
      "         -7.8824e-01,  5.2493e-01, -9.9614e-01,  2.8320e-01, -3.0696e-01,\n",
      "          2.0003e-01,  9.7612e-02,  3.4456e-03,  4.2026e-01, -4.2095e-01,\n",
      "         -7.7523e-02, -4.3970e-01, -1.2322e-01, -9.2096e-01,  5.1951e-01,\n",
      "         -4.4099e-01, -5.8768e-01, -1.5570e-02,  9.3897e-01, -1.4384e-01,\n",
      "         -6.9912e-01,  7.2026e-01,  7.0450e-01,  8.1244e-01],\n",
      "        [-7.7298e-01, -9.9869e-01,  5.9110e-01,  4.7257e-01, -5.4029e-01,\n",
      "          8.9320e-01, -9.0230e-01, -1.8596e-02,  7.5182e-01,  9.3296e-01,\n",
      "         -4.0903e-01, -3.7993e-01,  1.4398e-01, -6.2092e-01,  9.5674e-01,\n",
      "          2.6264e-01,  6.8811e-01, -5.1260e-01,  9.1324e-01, -9.7377e-01,\n",
      "          8.6499e-01, -4.3093e-01, -1.9006e-01,  5.9875e-01, -6.8819e-01,\n",
      "         -8.9139e-01, -9.1578e-01,  3.2361e-01, -9.7606e-02, -2.4662e-01,\n",
      "         -9.9952e-01,  6.1305e-01, -2.3655e-01,  3.9580e-01, -2.8046e-01,\n",
      "          4.5200e-01,  9.5078e-02, -6.7348e-02,  3.9203e-01,  4.0137e-01,\n",
      "         -6.1574e-01,  6.1273e-01,  8.0507e-01, -5.6010e-01, -5.3690e-01,\n",
      "         -8.7980e-01, -4.6528e-01,  1.6942e-01,  6.9008e-01,  3.3735e-01,\n",
      "         -3.8656e-02,  6.3426e-01,  3.0033e-04,  9.2376e-01,  5.0353e-01,\n",
      "          9.2714e-01,  7.9839e-02, -9.6047e-01,  7.6549e-02,  9.9765e-01,\n",
      "         -5.8875e-01,  3.3173e-01,  7.5947e-02, -1.1970e-01],\n",
      "        [-5.6112e-01, -5.0441e-01, -6.6068e-01, -9.5655e-01, -3.6252e-01,\n",
      "         -6.1656e-01,  3.9102e-01, -5.4165e-01, -6.9394e-01, -5.5144e-01,\n",
      "         -1.5320e-01, -8.8969e-01,  2.7347e-01, -6.1187e-01,  3.1434e-01,\n",
      "         -7.0129e-01,  1.2778e-01, -5.2391e-01, -4.6023e-01,  9.6325e-01,\n",
      "         -2.5725e-01, -1.2192e-01, -1.5572e-01,  6.0643e-01,  8.6148e-01,\n",
      "         -7.4486e-01,  6.4737e-01, -2.8151e-02,  1.3481e-01,  9.9406e-01,\n",
      "         -5.6152e-01,  4.0240e-01,  4.9971e-01, -5.6034e-01, -3.4200e-01,\n",
      "         -8.7762e-02, -1.5369e-01,  3.9810e-01, -7.3022e-01,  8.4159e-01,\n",
      "          1.4389e-01, -4.4584e-02,  1.3654e-03,  2.2103e-01, -2.3394e-01,\n",
      "         -1.7873e-01,  4.0250e-01,  7.0743e-01,  7.1897e-01,  2.0697e-01,\n",
      "          4.4771e-01,  7.9321e-01,  2.3514e-01, -4.5610e-02,  3.3125e-01,\n",
      "         -8.8763e-01,  5.4085e-01,  6.1394e-01, -6.0777e-01, -8.6581e-01,\n",
      "         -1.9583e-01,  4.6173e-01,  5.5364e-01, -9.0135e-01],\n",
      "        [-9.8873e-02, -6.9628e-02,  6.8231e-01, -6.6492e-01,  6.8469e-01,\n",
      "          1.7149e-01, -5.9447e-01,  9.6248e-01,  8.1407e-01, -1.4386e-01,\n",
      "          9.2120e-01, -3.7489e-01, -8.8235e-01, -6.7289e-01, -3.3768e-01,\n",
      "          9.6728e-01,  6.7019e-01, -3.2068e-01,  5.0846e-01, -8.6915e-01,\n",
      "          7.8843e-01,  4.4536e-01,  2.5541e-01,  4.7476e-01,  5.8589e-02,\n",
      "          8.4618e-01, -7.5568e-01,  3.9827e-01, -5.3083e-01, -6.3509e-02,\n",
      "         -6.5865e-01,  9.3092e-01, -8.2180e-01,  7.8566e-01, -7.4410e-01,\n",
      "          8.5812e-02, -1.1464e-01,  1.7945e-01,  7.4421e-01, -4.4174e-01,\n",
      "          3.7162e-01,  3.2631e-02, -3.3421e-01,  7.6976e-02,  4.5997e-01,\n",
      "          5.9012e-01, -9.3631e-01,  5.6656e-01, -3.1637e-01,  9.2540e-01,\n",
      "          6.7612e-01, -5.3068e-01,  2.4678e-01, -2.5364e-01,  7.6731e-01,\n",
      "          5.1392e-01, -3.4147e-01,  1.3359e-01, -4.5541e-01, -9.4750e-01,\n",
      "          1.5377e-01,  6.5186e-01, -4.8559e-01,  6.5332e-01]], device='cuda:0')\n",
      "tensor([[0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0601, -0.2638, -0.0075, -0.1026,  0.0840,  0.1801,  0.1399,  0.1473,\n",
       "          0.1354,  0.0799,  0.2612,  0.2260,  0.0583,  0.3097,  0.0861, -0.1621],\n",
       "        [-0.2847, -0.1465,  0.3910,  0.1419, -0.0216,  0.2647,  0.0731,  0.1530,\n",
       "         -0.1393, -0.2601, -0.1239,  0.3101,  0.0092,  0.0693, -0.2516, -0.2560],\n",
       "        [ 0.1839, -0.2090,  0.1885, -0.0120, -0.1155,  0.0942, -0.2914, -0.1912,\n",
       "          0.1138, -0.3456,  0.0674,  0.2487,  0.1117,  0.0846, -0.0811,  0.2475],\n",
       "        [ 0.0530,  0.0848, -0.5887, -0.2768, -0.1067, -0.2809, -0.0773,  0.0977,\n",
       "          0.1195,  0.3115,  0.3492, -0.1180,  0.1107,  0.1006,  0.5462, -0.0227]],\n",
       "       device='cuda:0', grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_city_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STGTrans",
   "language": "python",
   "name": "stgtrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
