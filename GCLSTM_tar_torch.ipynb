{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjkim/anaconda3/envs/STGTrans/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn import ChebConv\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "\n",
    "\n",
    "class GCLSTM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        in_channels (int): Number of input features.\n",
    "        out_channels (int): Number of output features.\n",
    "        K (int): Chebyshev filter size :math:`K`.\n",
    "        normalization (str, optional): The normalization scheme for the graph\n",
    "            Laplacian (default: :obj:`\"sym\"`):\n",
    "\n",
    "            1. :obj:`None`: No normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
    "\n",
    "            2. :obj:`\"sym\"`: Symmetric normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
    "            \\mathbf{D}^{-1/2}`\n",
    "\n",
    "            3. :obj:`\"rw\"`: Random-walk normalization\n",
    "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
    "\n",
    "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
    "            this operator in case the normalization is non-symmetric.\n",
    "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
    "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
    "            scalar/zero-dimensional tensor when operating on single graphs.\n",
    "            You can pre-compute :obj:`lambda_max` via the\n",
    "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
    "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
    "            an additive bias. (default: :obj:`True`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        K: int,\n",
    "        normalization: str = \"sym\",\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        super(GCLSTM, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.normalization = normalization\n",
    "        self.bias = bias\n",
    "        self._create_parameters_and_layers()\n",
    "        self._set_parameters()\n",
    "\n",
    "    def _create_input_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_i = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_i = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_i = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_forget_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_f = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_f = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_f = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_cell_state_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_c = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_c = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_c = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_output_gate_parameters_and_layers(self):\n",
    "\n",
    "        self.conv_o = ChebConv(\n",
    "            in_channels=self.out_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            K=self.K,\n",
    "            normalization=self.normalization,\n",
    "            bias=self.bias,\n",
    "        )\n",
    "\n",
    "        self.W_o = Parameter(torch.Tensor(self.in_channels, self.out_channels))\n",
    "        self.b_o = Parameter(torch.Tensor(1, self.out_channels))\n",
    "\n",
    "    def _create_parameters_and_layers(self):\n",
    "        self._create_input_gate_parameters_and_layers()\n",
    "        self._create_forget_gate_parameters_and_layers()\n",
    "        self._create_cell_state_parameters_and_layers()\n",
    "        self._create_output_gate_parameters_and_layers()\n",
    "\n",
    "    def _set_parameters(self):\n",
    "        glorot(self.W_i)\n",
    "        glorot(self.W_f)\n",
    "        glorot(self.W_c)\n",
    "        glorot(self.W_o)\n",
    "        zeros(self.b_i)\n",
    "        zeros(self.b_f)\n",
    "        zeros(self.b_c)\n",
    "        zeros(self.b_o)\n",
    "\n",
    "    def _set_hidden_state(self, X, H):\n",
    "        if H is None:\n",
    "            H = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return H\n",
    "\n",
    "    def _set_cell_state(self, X, C):\n",
    "        if C is None:\n",
    "            C = torch.zeros(X.shape[0], self.out_channels).to(X.device)\n",
    "        return C\n",
    "\n",
    "    def _calculate_input_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        I = torch.matmul(X, self.W_i)\n",
    "        I = I + self.conv_i(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        I = I + self.b_i\n",
    "        I = torch.sigmoid(I)\n",
    "        return I\n",
    "\n",
    "    def _calculate_forget_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        F = torch.matmul(X, self.W_f)\n",
    "        F = F + self.conv_f(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        F = F + self.b_f\n",
    "        F = torch.sigmoid(F)\n",
    "        return F\n",
    "\n",
    "    def _calculate_cell_state(self, X, edge_index, edge_weight, H, C, I, F, lambda_max):\n",
    "        T = torch.matmul(X, self.W_c)\n",
    "        T = T + self.conv_c(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        T = T + self.b_c\n",
    "        T = torch.tanh(T)\n",
    "        C = F * C + I * T\n",
    "        return C\n",
    "\n",
    "    def _calculate_output_gate(self, X, edge_index, edge_weight, H, C, lambda_max):\n",
    "        O = torch.matmul(X, self.W_o)\n",
    "        O = O + self.conv_o(H, edge_index, edge_weight, lambda_max=lambda_max)\n",
    "        O = O + self.b_o\n",
    "        O = torch.sigmoid(O)\n",
    "        return O\n",
    "\n",
    "    def _calculate_hidden_state(self, O, C):\n",
    "        H = O * torch.tanh(C)\n",
    "        return H\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.FloatTensor,\n",
    "        edge_index: torch.LongTensor,\n",
    "        edge_weight: torch.FloatTensor = None,\n",
    "        H: torch.FloatTensor = None,\n",
    "        C: torch.FloatTensor = None,\n",
    "        lambda_max: torch.Tensor = None,\n",
    "    ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        Making a forward pass. If edge weights are not present the forward pass\n",
    "        defaults to an unweighted graph. If the hidden state and cell state\n",
    "        matrices are not present when the forward pass is called these are\n",
    "        initialized with zeros.\n",
    "\n",
    "        Arg types:\n",
    "            * **X** *(PyTorch Float Tensor)* - Node features.\n",
    "            * **edge_index** *(PyTorch Long Tensor)* - Graph edge indices.\n",
    "            * **edge_weight** *(PyTorch Long Tensor, optional)* - Edge weight vector.\n",
    "            * **H** *(PyTorch Float Tensor, optional)* - Hidden state matrix for all nodes.\n",
    "            * **C** *(PyTorch Float Tensor, optional)* - Cell state matrix for all nodes.\n",
    "            * **lambda_max** *(PyTorch Tensor, optional but mandatory if normalization is not sym)* - Largest eigenvalue of Laplacian.\n",
    "\n",
    "        Return types:\n",
    "            * **H** *(PyTorch Float Tensor)* - Hidden state matrix for all nodes.\n",
    "            * **C** *(PyTorch Float Tensor)* - Cell state matrix for all nodes.\n",
    "        \"\"\"\n",
    "        H = self._set_hidden_state(X, H)\n",
    "        C = self._set_cell_state(X, C)\n",
    "        I = self._calculate_input_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        F = self._calculate_forget_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        C = self._calculate_cell_state(X, edge_index, edge_weight, H, C, I, F, lambda_max)\n",
    "        O = self._calculate_output_gate(X, edge_index, edge_weight, H, C, lambda_max)\n",
    "        H = self._calculate_hidden_state(O, C)\n",
    "        return H, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def create_mock_data(number_of_nodes, edge_per_node, in_channels):\n",
    "    \"\"\"\n",
    "    Creating a mock feature matrix and edge index.\n",
    "    \"\"\"\n",
    "    graph = nx.watts_strogatz_graph(number_of_nodes, edge_per_node, 0.5)\n",
    "    edge_index = torch.LongTensor(np.array([edge for edge in graph.edges()]).T)\n",
    "    X = torch.FloatTensor(np.random.uniform(-1, 1, (number_of_nodes, in_channels)))\n",
    "    #X = torch.FloatTensor(np.resize(np.arange(number_of_nodes), (in_channels, number_of_nodes)).T)\n",
    "    return X, edge_index\n",
    "\n",
    "def create_mock_edge_weight(edge_index):\n",
    "    \"\"\"\n",
    "    Creating a mock edge weight tensor.\n",
    "    \"\"\"\n",
    "    return torch.FloatTensor(np.random.uniform(0, 1, (edge_index.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_hop_based_subgraph_generator_BFS(k, feature_vector, adjacency_matrix):\n",
    "    N = len(feature_vector)        \n",
    "    subgraphs = []\n",
    "\n",
    "    def BFS(u):\n",
    "        visit = [False] * N\n",
    "        qu = [(u, 0)]\n",
    "        visit[u] = True\n",
    "        ret = []\n",
    "\n",
    "        while len(qu) > 0:\n",
    "            u, dist = qu.pop(0)\n",
    "            if dist > k:\n",
    "                break\n",
    "            ret.append(u)\n",
    "\n",
    "            for v in range(N):\n",
    "                if adjacency_matrix[u][v] == 1 and visit[v] == False:\n",
    "                    qu.append((v, dist + 1))\n",
    "                    visit[v] = True\n",
    "        return ret    \n",
    "    \n",
    "    for i in range(N):\n",
    "        candidate_list = BFS(i)\n",
    "        sub_feature = feature_vector[candidate_list]\n",
    "        sub_adj = adjacency_matrix[:,candidate_list][candidate_list,:]\n",
    "        subgraphs.append([sub_feature, sub_adj])\n",
    "    return subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tar_city_model():\n",
    "\n",
    "    number_of_nodes = 4\n",
    "    edge_per_node = 2\n",
    "    \n",
    "    in_channels = 64\n",
    "    out_channels = 16\n",
    "    K = 2\n",
    "    k = 1\n",
    "    number_of_layers = 5\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X, edge_index = create_mock_data(number_of_nodes, edge_per_node, in_channels)\n",
    "    X = X.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_weight = torch.FloatTensor(np.ones(edge_index.shape[1])).to(device)\n",
    "    adj = torch.FloatTensor(np.zeros((number_of_nodes, number_of_nodes))).to(device)\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        adj[edge_index[0][i]][edge_index[1][i]] = edge_weight[i]\n",
    "        adj[edge_index[1][i]][edge_index[0][i]] = edge_weight[i]\n",
    "    \n",
    "    print(X)\n",
    "    print(adj)\n",
    "\n",
    "    subgraph = k_hop_based_subgraph_generator_BFS(k, X, adj)\n",
    "    subGCLSTM = []\n",
    "\n",
    "    for sub_feature, sub_adj in subgraph:\n",
    "        layer = GCLSTM(in_channels=in_channels, out_channels=out_channels, K=K).to(device)\n",
    "\n",
    "        edges = []\n",
    "        for i in range(len(sub_adj)):\n",
    "            for j in range(len(sub_adj[0])):\n",
    "                if sub_adj[i][j] == 1:\n",
    "                    edges.append([i, j])\n",
    "        \n",
    "        X = sub_feature\n",
    "        edge_index = torch.LongTensor(np.array(edges).T).to(device)\n",
    "        edge_weight = torch.FloatTensor(np.ones(edge_index.shape[1])).to(device)\n",
    "        \n",
    "        #print(X.shape)\n",
    "        #print(edge_index.shape)\n",
    "        #print(edge_weight.shape)\n",
    "\n",
    "        for i in range(number_of_layers):\n",
    "            if i == 0:\n",
    "                H, C = layer(X, edge_index, edge_weight)\n",
    "            else:\n",
    "                H, C = layer(X, edge_index, edge_weight, H, C)\n",
    "        \n",
    "        #subGCLSTM.append([H, C])\n",
    "        subGCLSTM.append(H[0])\n",
    "    \n",
    "    subGCLSTM = torch.stack(subGCLSTM, 0)\n",
    "    \n",
    "    return subGCLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9688e-01, -6.2442e-01, -8.4654e-01,  9.0288e-01, -1.2188e-01,\n",
      "          1.0943e-01,  1.0685e-01,  6.3113e-01, -9.0448e-01, -7.2135e-01,\n",
      "         -7.3216e-01,  9.5887e-01,  5.2013e-01,  6.9237e-01,  5.7520e-01,\n",
      "          4.4226e-01,  7.3227e-01, -8.2984e-01,  1.3687e-01,  4.7502e-01,\n",
      "         -9.9719e-01, -1.3444e-01, -6.2768e-01,  8.8830e-01,  3.3954e-01,\n",
      "         -7.6304e-01,  5.0844e-01,  7.7361e-01, -1.8637e-02, -9.6821e-01,\n",
      "          7.8430e-02,  9.0718e-01, -6.2693e-01, -2.4073e-01, -2.8049e-01,\n",
      "          8.1025e-03,  4.9677e-02, -5.6954e-01,  9.1469e-01, -9.5053e-01,\n",
      "          5.6249e-01,  6.1196e-01, -3.3739e-01, -9.5040e-01,  4.1490e-01,\n",
      "          7.9384e-01,  1.6259e-01, -6.9614e-01,  1.2874e-01, -7.6601e-01,\n",
      "          6.6441e-01, -6.5492e-01,  3.5661e-01, -2.4235e-04,  1.5453e-02,\n",
      "          2.7323e-01,  5.5767e-01, -2.8122e-01,  7.6146e-01, -3.0145e-01,\n",
      "         -1.5504e-01, -2.1270e-01,  4.5350e-01, -1.7934e-01],\n",
      "        [-1.3760e-01, -1.6416e-01, -2.9669e-01, -3.1844e-01, -2.5318e-01,\n",
      "         -6.9970e-01, -8.9731e-01, -4.6234e-01, -5.9909e-01,  6.4038e-01,\n",
      "          6.9302e-01,  5.4240e-01, -9.6008e-01,  5.0158e-02,  5.4947e-01,\n",
      "          9.7340e-01,  4.6526e-01, -2.9551e-01, -3.8112e-01,  2.1102e-01,\n",
      "         -8.7002e-01, -8.1316e-01, -9.4633e-01, -5.0984e-01, -9.3291e-01,\n",
      "          2.2201e-01, -6.6752e-01,  4.9485e-01,  3.5109e-01, -6.5254e-01,\n",
      "          6.7219e-01, -3.0324e-01,  6.6087e-01,  5.5842e-01, -3.0462e-01,\n",
      "          7.9443e-01,  8.6529e-01,  8.8947e-01, -1.2083e-01,  8.0610e-01,\n",
      "         -3.9772e-01,  1.3928e-01, -9.6986e-02,  8.9939e-01, -5.3125e-01,\n",
      "         -4.8905e-01, -4.4347e-03,  6.5828e-01, -4.7646e-01, -5.8267e-01,\n",
      "          5.6290e-01, -7.7431e-01,  6.7064e-01, -8.8024e-01, -4.7240e-01,\n",
      "         -9.5785e-01,  7.1701e-01,  8.8767e-01,  6.3974e-01,  2.6758e-01,\n",
      "          9.7571e-01,  7.9482e-01,  5.3922e-01,  3.7776e-01],\n",
      "        [ 5.1547e-01,  6.4591e-02, -8.6640e-01,  9.9620e-01, -8.0839e-01,\n",
      "         -3.4297e-01,  8.7701e-01,  7.8074e-01,  4.7654e-01,  8.9780e-01,\n",
      "          4.3652e-01, -4.5885e-02, -9.3121e-02, -6.7076e-01, -7.2506e-01,\n",
      "          2.0103e-01,  4.4493e-01, -9.4910e-01, -1.8261e-03,  4.7359e-01,\n",
      "          9.6677e-01, -8.0603e-01, -6.8728e-01, -9.6906e-01, -7.3838e-01,\n",
      "          4.9643e-01,  8.1319e-02, -8.0828e-01,  9.1281e-01, -3.5987e-01,\n",
      "          3.0634e-01, -2.8400e-01, -4.9637e-01, -5.2005e-01, -7.1470e-01,\n",
      "          3.8305e-01, -3.1615e-02, -3.6437e-01, -5.6039e-01, -2.6241e-01,\n",
      "         -5.2885e-01,  8.4244e-01,  8.9458e-01,  8.6834e-01,  8.5529e-01,\n",
      "          4.3282e-02, -9.1337e-01, -7.9650e-01,  5.0265e-01,  6.5712e-01,\n",
      "         -3.7846e-02, -9.0946e-01, -5.6004e-01, -1.3680e-01,  4.1142e-01,\n",
      "          3.5638e-01, -5.4656e-03,  1.7475e-01,  5.6236e-01, -6.7670e-01,\n",
      "          7.4262e-01,  6.8209e-01,  8.2308e-01,  3.4055e-01],\n",
      "        [ 7.5747e-01, -9.6063e-01,  9.0209e-01,  4.7371e-01, -1.0589e-01,\n",
      "         -7.8131e-01,  1.2033e-01,  4.7545e-01, -3.1580e-01,  9.4110e-01,\n",
      "         -2.6571e-01, -6.6757e-01,  2.9914e-01,  6.0383e-01,  2.8238e-01,\n",
      "         -5.6112e-01, -8.3484e-01, -2.0673e-01, -8.5964e-01, -7.0650e-01,\n",
      "         -6.3356e-01, -1.9851e-01, -8.5137e-01,  5.9225e-01,  7.6328e-01,\n",
      "         -6.6261e-01, -1.3711e-01, -5.8207e-01, -8.9482e-01, -1.1536e-01,\n",
      "          8.3075e-01, -4.5598e-01, -7.3904e-01, -4.2167e-01,  6.8361e-01,\n",
      "          6.9758e-02, -1.5444e-01, -9.4098e-01,  7.5486e-01,  5.0057e-01,\n",
      "          9.4345e-01,  5.0583e-01, -2.8464e-01, -6.0972e-01, -8.9683e-01,\n",
      "         -1.0173e-01, -9.2491e-01,  6.7082e-01, -4.4436e-01,  7.7433e-01,\n",
      "          9.7571e-01, -1.6701e-02, -6.0609e-01,  7.3771e-01,  5.0879e-01,\n",
      "         -8.5195e-02,  9.6628e-01,  9.2619e-03, -8.0403e-01, -5.0584e-01,\n",
      "          5.3737e-01,  4.0289e-01,  4.6808e-01,  9.9130e-01]], device='cuda:0')\n",
      "tensor([[0., 1., 0., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 1., 1., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3143,  0.3424,  0.4997,  0.4018,  0.2919,  0.2208,  0.3149, -0.1876,\n",
       "          0.2231, -0.3326,  0.0305, -0.0267,  0.0080, -0.0601, -0.3850,  0.1907],\n",
       "        [-0.1015,  0.0262, -0.7688,  0.2065,  0.0045,  0.1151, -0.3001,  0.2636,\n",
       "          0.4097, -0.3077, -0.4377,  0.2022,  0.1087, -0.4507, -0.0086, -0.1611],\n",
       "        [ 0.1511,  0.1041, -0.0163,  0.2887, -0.3903, -0.0236,  0.5719,  0.2249,\n",
       "         -0.0613,  0.0103,  0.1467, -0.0134, -0.0782,  0.0528,  0.2347, -0.1186],\n",
       "        [ 0.0158, -0.1025, -0.1960, -0.1387, -0.4104, -0.0669, -0.2548, -0.5697,\n",
       "         -0.0173, -0.1488,  0.5804,  0.3054,  0.4924,  0.2643, -0.1180,  0.3707]],\n",
       "       device='cuda:0', grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_city_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7015,  0.7190,  0.8282, -0.4113,  0.7139, -0.8206,  0.9074, -0.5064,\n",
      "         -0.6740, -0.7118, -0.0896,  0.6049,  0.1442, -0.2489,  0.4248,  0.1383,\n",
      "         -0.8398, -0.5556,  0.9540,  0.8415,  0.0871, -0.5700, -0.9011,  0.0491,\n",
      "          0.9962,  0.5597,  0.1744, -0.1462,  0.7769, -0.6330, -0.0785, -0.1797,\n",
      "          0.7256, -0.6184,  0.5107, -0.4516,  0.1102, -0.7135,  0.0948,  0.6320,\n",
      "          0.6777, -0.7451, -0.4012,  0.3777,  0.1393,  0.9869,  0.7218,  0.3166,\n",
      "          0.2912,  0.4273,  0.3678, -0.8668,  0.4619,  0.6338, -0.9946, -0.4875,\n",
      "          0.6419,  0.7407, -0.0352, -0.0258,  0.5778,  0.3292,  0.5178,  0.9417],\n",
      "        [-0.5871,  0.8162, -0.6052, -0.0746, -0.5255,  0.6210,  0.2312,  0.9470,\n",
      "         -0.8650,  0.3463,  0.1809,  0.1191, -0.7839,  0.1871,  0.8393,  0.4179,\n",
      "         -0.8000, -0.7423,  0.1952, -0.3607,  0.0377,  0.7135,  0.6842, -0.4546,\n",
      "          0.1563,  0.8178,  0.9238,  0.7610,  0.1599,  0.3040, -0.1780, -0.0716,\n",
      "         -0.6596, -0.4401,  0.7544,  0.7407,  0.0737,  0.1564,  0.0966,  0.1087,\n",
      "         -0.6977, -0.4550, -0.5332, -0.8285, -0.7598, -0.4727, -0.7685, -0.1131,\n",
      "          0.0420, -0.6116,  0.7274, -0.9657,  0.6476, -0.9766, -0.2946,  0.1092,\n",
      "         -0.3670,  0.1066,  0.1954, -0.3346, -0.7465,  0.6314, -0.4620, -0.9390],\n",
      "        [ 0.5359, -0.1172, -0.3660, -0.6275,  0.7350, -0.0843,  0.1794,  0.1629,\n",
      "          0.8300, -0.8516, -0.9670, -0.9221, -0.5709,  0.6986,  0.5062, -0.8406,\n",
      "          0.9125, -0.1331, -0.8490,  0.7508, -0.8841,  0.1497, -0.9998, -0.0876,\n",
      "          0.7855, -0.2127,  0.8934, -0.1401, -0.4178, -0.9777, -0.1497,  0.2797,\n",
      "          0.2960,  0.3029,  0.4995, -0.0728,  0.9237,  0.4445,  0.7198,  0.3144,\n",
      "         -0.5914,  0.2749, -0.0169, -0.4682, -0.5287, -0.4921,  0.5969, -0.3765,\n",
      "         -0.2023,  0.0469, -0.1014, -0.1264, -0.5182, -0.3365, -0.8951,  0.0573,\n",
      "         -0.4648, -0.8231, -0.2707,  0.0205, -0.4053, -0.7529, -0.3660,  0.0371],\n",
      "        [ 0.3672, -0.4813, -0.4186, -0.0858, -0.7733,  0.3667, -0.1486, -0.9526,\n",
      "         -0.5570, -0.0037,  0.0676, -0.8390,  0.2293,  0.3962,  0.9840, -0.4966,\n",
      "         -0.2200,  0.3679, -0.0907, -0.1248, -0.6223,  0.7570,  0.2852,  0.4408,\n",
      "          0.3920,  0.7700, -0.3728,  0.6267, -0.1749, -0.7049, -0.2828, -0.7540,\n",
      "          0.2440,  0.9125, -0.7048, -0.6185,  0.6531, -0.3130,  0.5678,  0.1771,\n",
      "          0.9099,  0.3013,  0.5397,  0.6687,  0.7607,  0.9704,  0.9495,  0.4983,\n",
      "          0.6645,  0.2801,  0.6507,  0.2862,  0.8983, -0.5912,  0.1395, -0.3098,\n",
      "         -0.1508,  0.9605, -0.3115, -0.1842, -0.4231, -0.5200,  0.9744, -0.1240]],\n",
      "       device='cuda:0')\n",
      "tensor([[0., 1., 1., 1.],\n",
      "        [1., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 1., 0., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m tar_city_model()\n\u001b[0;32m----> 5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50\u001b[39m)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = tar_city_model()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        cost = torch.mean((y_hat-snapshot.y)**2)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STGTrans",
   "language": "python",
   "name": "stgtrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
